# main model 
# MobileNetV4 main code network reference https://github.com/huggingface/pytorch-image-models
# Some functions and code are adapted and referenced from official repositories
# 
from typing import Optional
import torch
import torch.nn as nn


def make_divisible(value: float,divisor: int,min_value: Optional[float] = None,round_down_protect: bool = True,) -> int:
    if min_value is None:
        min_value = divisor
    new_value = max(min_value, int(value + divisor / 2) // divisor * divisor)
    if round_down_protect and new_value < 0.9 * value:
        new_value += divisor
    return int(new_value)


def conv_2d(inp, oup, kernel_size=3, stride=1, groups=1, bias=False, norm=True, act=True):
    conv = nn.Sequential()
    padding = (kernel_size - 1) // 2
    conv.add_module('conv', nn.Conv2d(inp, oup, kernel_size, stride, padding, bias=bias, groups=groups))
    if norm:
        conv.add_module('BatchNorm2d', nn.BatchNorm2d(oup))
    if act:
        conv.add_module('Activation', nn.ReLU6())
    return conv


# upsamp_blocks
def build_up_blocks(spec):
    layers = []
    for in_channels, out_channels, kernel_size, stride in spec['block_specs']:
        layers.append(nn.Upsample(scale_factor=2))
        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True))
        layers.append(nn.BatchNorm2d(out_channels))
    return nn.Sequential(*layers)


class UniversalInvertedBottleneckBlock(nn.Module):
    def __init__(self,inp, oup,start_dw_kernel_size,middle_dw_kernel_size, middle_dw_downsample,
                 stride,
                 expand_ratio
                 ):
        super().__init__()
        self.start_dw_kernel_size = start_dw_kernel_size
        if self.start_dw_kernel_size:
            stride_ = stride if not middle_dw_downsample else 1
            self._start_dw_ = conv_2d(inp, inp, kernel_size=start_dw_kernel_size, stride=stride_, groups=inp, act=False)
        # Expansion with 1x1 convs.
        expand_filters = make_divisible(inp * expand_ratio, 8)
        self._expand_conv = conv_2d(inp, expand_filters, kernel_size=1)
        # Middle depthwise conv.
        self.middle_dw_kernel_size = middle_dw_kernel_size
        if self.middle_dw_kernel_size:
            stride_ = stride if middle_dw_downsample else 1
            self._middle_dw = conv_2d(expand_filters, expand_filters, kernel_size=middle_dw_kernel_size, stride=stride_,
                                      groups=expand_filters)
        self._proj_conv = conv_2d(expand_filters, oup, kernel_size=1, stride=1, act=False)

    def forward(self, x):
        if self.start_dw_kernel_size:
            x = self._start_dw_(x)
        x = self._expand_conv(x)
        if self.middle_dw_kernel_size:
            x = self._middle_dw(x)
        x = self._proj_conv(x)
        return x



def build_blocks(layer_spec):
    if not layer_spec.get('block_name'):
        return nn.Sequential()
    block_names = layer_spec['block_name']
    layers = nn.Sequential()
    if block_names == "convbn":
        schema_ = ['inp', 'oup', 'kernel_size', 'stride']
        for i in range(layer_spec['num_blocks']):
            args = dict(zip(schema_, layer_spec['block_specs'][i]))
            layers.add_module(f"convbn_{i}", conv_2d(**args))
    elif block_names == "uib":
        schema_ = ['inp', 'oup', 'start_dw_kernel_size', 'middle_dw_kernel_size', 'middle_dw_downsample', 'stride',
                   'expand_ratio', 'mhsa']
        for i in range(layer_spec['num_blocks']):
            args = dict(zip(schema_, layer_spec['block_specs'][i]))
            layers.add_module(f"uib_{i}", UniversalInvertedBottleneckBlock(**args))
    else:
        raise NotImplementedError
    return layers


class ChannelAttention(nn.Module):
    def __init__(self, channel, reduction=16):
        super().__init__()
        self.maxpool = nn.AdaptiveMaxPool2d(1)
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.se = nn.Sequential(
            nn.Conv2d(channel, channel // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(channel // reduction, channel, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        max_result = self.maxpool(x)
        avg_result = self.avgpool(x)
        max_out = self.se(max_result)
        avg_out = self.se(avg_result)
        output = self.sigmoid(max_out + avg_out)
        return output


class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        max_result, _ = torch.max(x, dim=1, keepdim=True)
        avg_result = torch.mean(x, dim=1, keepdim=True)
        result = torch.cat([max_result, avg_result], 1)
        output = self.conv(result)
        output = self.sigmoid(output)
        return output


class CBAMBlock(nn.Module):
    def __init__(self, channel=512, reduction=16, kernel_size=49):
        super().__init__()
        self.ca = ChannelAttention(channel=channel, reduction=reduction)
        self.sa = SpatialAttention(kernel_size=kernel_size)

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='CBAM_out')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        b, c, _, _ = x.size()
        residual = x
        out = x * self.ca(x)
        out = out * self.sa(out)
        return out + residual


class BL_Unet(nn.Module):
    def __init__(self, in_ch=3, out_ch=4):
        super().__init__()
        self.spec = {
            "conv0": {
                "block_name": "convbn",
                "num_blocks": 1,
                "block_specs": [
                    [in_ch, 32, 3, 2]
                ]
            },
            "layer1": {
                "block_name": "convbn",
                "num_blocks": 2,
                "block_specs": [
                    [32, 32, 3, 2],
                    [32, 32, 1, 1]
                ]
            },
            "layer2": {
                "block_name": "convbn",
                "num_blocks": 2,
                "block_specs": [
                    [32, 96, 3, 2],
                    [96, 64, 1, 1]
                ]
            },
            "layer3": {
                "block_name": "uib",
                "num_blocks": 6,
                "block_specs": [
                    [64, 96, 5, 5, True, 2, 3],
                    [96, 96, 0, 3, True, 1, 2],
                    [96, 96, 0, 3, True, 1, 2],
                    [96, 96, 0, 3, True, 1, 2],
                    [96, 96, 0, 3, True, 1, 2],
                    [96, 96, 3, 0, True, 1, 4],
                ]
            },
            "layer4": {
                "block_name": "uib",
                "num_blocks": 6,
                "block_specs": [
                    [96, 128, 3, 3, True, 2, 6],
                    [128, 128, 5, 5, True, 1, 4],
                    [128, 128, 0, 5, True, 1, 4],
                    [128, 128, 0, 5, True, 1, 3],
                    [128, 128, 0, 3, True, 1, 4],
                    [128, 128, 0, 3, True, 1, 4],
                ]
            },
            "layer5": {
                "block_name": "convbn",
                "num_blocks": 3,
                "block_specs": [
                    [128, 256, 1, 1],
                    [256, 512, 1, 1],
                    [512, 128, 1, 1]
                ]
            }
        }
        self.conv0 = build_blocks(self.spec['conv0'])
        self.layer1 = build_blocks(self.spec['layer1'])
        self.layer2 = build_blocks(self.spec['layer2'])
        self.layer3 = build_blocks(self.spec['layer3'])
        self.layer4 = build_blocks(self.spec['layer4'])
        self.layer5 = build_blocks(self.spec['layer5'])
        self.cbam_L1 = CBAMBlock(channel=64, reduction=16, kernel_size=3)
        self.conv1 = nn.Sequential(
            nn.Conv2d(128+128, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.002,inplace=True),
            nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.002,inplace=True))
        self.conv2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002,inplace=True),
            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002, inplace=True),
            nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.002,inplace=True))
        self.conv3 = nn.Sequential(
            nn.Conv2d(96*2, 128, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002,inplace=True),
            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002, inplace=True),
            nn.Conv2d(128, 96*2, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(96*2),
            nn.LeakyReLU(0.002,inplace=True))
        self.conv4 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002,inplace=True),
            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.002, inplace=True),
            nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.002,inplace=True))


        self.uplayer1 = nn.Sequential(nn.Upsample(scale_factor=4),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64))
        self.uplayer2 = nn.Sequential(nn.Upsample(scale_factor=2),
            nn.Conv2d(96, 64, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(64))
        self.uplayer3 = nn.Sequential(nn.Upsample(scale_factor=4),
            nn.Conv2d(64*3, 32, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 32, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(32))
        self.uplayer4 = nn.Sequential(nn.Upsample(scale_factor=2),
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, out_ch, kernel_size=1, stride=1, padding=0, bias=True))
        self.cbam1 = CBAMBlock(channel=64, reduction=16, kernel_size=7)
        self.cbam2 = CBAMBlock(channel=96*2, reduction=16, kernel_size=7)
        self.cbam3 = CBAMBlock(channel=64, reduction=16, kernel_size=7)
    def forward(self, x):
        x0 = self.conv0(x)
        x1 = self.layer1(x0)
        x2 = self.layer2(x1)
        x3 = self.layer3(x2)
        x4 = self.layer4(x3)
        x5 = self.layer5(x4)
        up1 = torch.cat([x4, x5], dim=1)
        up1 = self.conv1(up1)
        up1 = self.cbam1(up1)
        up1 = self.uplayer1(up1)
        up2 = self.uplayer2(x3)
        up2 = self.conv2(up2)
        up4 = torch.cat([up1,up2, x2], dim=1)
        up4 = self.conv3(up4)
        up4 = self.cbam2(up4)
        up4 = self.uplayer3(up4)
        up5 = torch.cat([up4, x0], dim=1)
        up5 = self.conv4(up5)
        up5 = self.cbam3(up5)
        out = self.uplayer4(up5)
        return out


import torch
from torchinfo import summary
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
input_data = torch.randn(1, 3, 256, 256)
input_data = input_data.to(device)
# load model
model = BL_Unet(in_ch=3,out_ch=5)
model = model.to(device)
summary(model, input_size=(1, 3, 256, 256))



